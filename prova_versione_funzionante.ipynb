{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7e1ee2",
   "metadata": {},
   "source": [
    "# Enhancing Query Recommendations Through User Behavior Analysis\n",
    "\n",
    "This notebook re-implements the main ideas from the paper *Knowledge-Augmented Large Language Models for Personalized Contextual Query Suggestion (K-LaMP)*.  \n",
    "The goal is to build a lightweight entity-centric knowledge store from user search histories and browsing activities, and use it to enhance Large Language Models with personalized context. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f8c5f8",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "[1. Import libraries & Loading of the Datasets](#1-import-libraries--loading-of-the-datasets)  \n",
    "[2. Setup & small text utils](#2-setup--small-text-utils)  \n",
    "[3. Memory Stream Construction](#3-memory-stream-construction)  \n",
    "[4. Entity Store Construction](#4-entity-store-construction)  \n",
    "[5. User & Session Modeling](#5-user--session-modeling)  \n",
    "[6. Pick K_entities from session history and context](#6-pick-k_entities-from-session-history-and-context)  \n",
    "[7. Prompt Builder for Gemini K LaMP style](#7-prompt-builder-for-gemini-k-lamp-style)    \n",
    "[8. Gemini API Setup](#8-gemini-api-setup)  \n",
    "[9. User Initialization and Session Logging](#9-user-initialization-and-session-logging)  \n",
    "[10. Next Query Generation](#10-next-query-generation)  \n",
    "[11. Conclusions & Next Steps](#11-conclusions--next-steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96612f94",
   "metadata": {},
   "source": [
    "## 1. Import libraries & Loading of the Datasets\n",
    "\n",
    "This section imports libraries and loads the datasets used for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd73964",
   "metadata": {},
   "source": [
    "**Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "55a1eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json, re, time\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import google.generativeai as genai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9575b42d",
   "metadata": {},
   "source": [
    "**Data Loading**\n",
    "\n",
    "This section loads the three core datasets required for the project:\n",
    "- POI information (`poi_info_updated.csv`) containing points of interest (POI) and related metadata.\n",
    "- Descriptions (`data_descr_en_updated.csv`) with English textual descriptions of the POIs. \n",
    "- User profiles (`User Profiles.csv`) with ORCID information, past queries, and personal details. \n",
    "\n",
    "JSON‑like columns are parsed into Python lists to preserve multi‑valued fields (e.g., ORCID keywords, previous queries, POI answers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d6c12dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POI dataset shape: (78, 6)\n",
      "Descriptions dataset shape: (77, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi_id</th>\n",
       "      <th>poi_name</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>Basilica di Santa Anastasia</td>\n",
       "      <td>1</td>\n",
       "      <td>Chiese</td>\n",
       "      <td>16673.45.00</td>\n",
       "      <td>45.445.176.000.000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>complesso del Duomo</td>\n",
       "      <td>1</td>\n",
       "      <td>Chiese</td>\n",
       "      <td>166142.21.00</td>\n",
       "      <td>4.544.707.660.000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>Chiesa di San Bernardino</td>\n",
       "      <td>1</td>\n",
       "      <td>Chiese</td>\n",
       "      <td>163530.46.00</td>\n",
       "      <td>73195.54.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>Chiesa di Santa Maria in Organo</td>\n",
       "      <td>1</td>\n",
       "      <td>Chiese</td>\n",
       "      <td>729.57.00</td>\n",
       "      <td>74111.56.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>Chiesa di San Lorenzo</td>\n",
       "      <td>1</td>\n",
       "      <td>Chiese</td>\n",
       "      <td>165261.42.00</td>\n",
       "      <td>73567.17.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   poi_id                         poi_name  category_id category_name  \\\n",
       "0      54      Basilica di Santa Anastasia            1        Chiese   \n",
       "1      52              complesso del Duomo            1        Chiese   \n",
       "2      70         Chiesa di San Bernardino            1        Chiese   \n",
       "3      74  Chiesa di Santa Maria in Organo            1        Chiese   \n",
       "4      51            Chiesa di San Lorenzo            1        Chiese   \n",
       "\n",
       "      longitude                latitude  \n",
       "0   16673.45.00  45.445.176.000.000.000  \n",
       "1  166142.21.00   4.544.707.660.000.000  \n",
       "2  163530.46.00             73195.54.00  \n",
       "3     729.57.00             74111.56.00  \n",
       "4  165261.42.00             73567.17.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>nationality</th>\n",
       "      <th>previous_queries</th>\n",
       "      <th>orcid__id</th>\n",
       "      <th>orcid__keywords</th>\n",
       "      <th>Personal Interest</th>\n",
       "      <th>Profession</th>\n",
       "      <th>POI_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u1</td>\n",
       "      <td>England</td>\n",
       "      <td>[Best restaurants in Verona, Top-rated museums...</td>\n",
       "      <td>0000-0002-1825-0097</td>\n",
       "      <td>[machine learning, natural language processing...</td>\n",
       "      <td>[Artificial Intelligence, technology, travel, ...</td>\n",
       "      <td>mathematics professor</td>\n",
       "      <td>[Trattoria al Pompiere, Museo di Castelvecchio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u2</td>\n",
       "      <td>Italy</td>\n",
       "      <td>[Best ice cream in Verona, Is the Castel San P...</td>\n",
       "      <td>0000-0001-6092-6831</td>\n",
       "      <td>[database, data science, ethics in data manage...</td>\n",
       "      <td>[photograph, museum, history, books, reading, ...</td>\n",
       "      <td>database management professor</td>\n",
       "      <td>[Gelateria La Romana, Funicolare di Castel San...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u3</td>\n",
       "      <td>Italy</td>\n",
       "      <td>[Is there a tourist information office near th...</td>\n",
       "      <td>0000-0002-9809-1005</td>\n",
       "      <td>[diabetes, metabolism, pancreatic beta cell fu...</td>\n",
       "      <td>[nature, hiking, pets, religion, dogs, walking]</td>\n",
       "      <td>Physician</td>\n",
       "      <td>[IAT Verona Centro, Museo Lapidario Maffeiano,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u4</td>\n",
       "      <td>USA</td>\n",
       "      <td>[24/7 parking near the Arena for an evening sh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[sports, nba, Movies, Computer, beer]</td>\n",
       "      <td>Student</td>\n",
       "      <td>[Parcheggio Arena (SABA), Stadio Marcantonio B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u5</td>\n",
       "      <td>India</td>\n",
       "      <td>[Best ice cream in Verona, Is the Castel San P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Researcher, Sport Teacher, handball and Bodyb...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Sport science researcher</td>\n",
       "      <td>[Gelateria La Romana, Funicolare di Castel San...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id nationality                                   previous_queries  \\\n",
       "0      u1     England  [Best restaurants in Verona, Top-rated museums...   \n",
       "1      u2       Italy  [Best ice cream in Verona, Is the Castel San P...   \n",
       "2      u3       Italy  [Is there a tourist information office near th...   \n",
       "3      u4         USA  [24/7 parking near the Arena for an evening sh...   \n",
       "4      u5       India  [Best ice cream in Verona, Is the Castel San P...   \n",
       "\n",
       "             orcid__id                                    orcid__keywords  \\\n",
       "0  0000-0002-1825-0097  [machine learning, natural language processing...   \n",
       "1  0000-0001-6092-6831  [database, data science, ethics in data manage...   \n",
       "2  0000-0002-9809-1005  [diabetes, metabolism, pancreatic beta cell fu...   \n",
       "3                  NaN                                                 []   \n",
       "4                  NaN  [Researcher, Sport Teacher, handball and Bodyb...   \n",
       "\n",
       "                                   Personal Interest  \\\n",
       "0  [Artificial Intelligence, technology, travel, ...   \n",
       "1  [photograph, museum, history, books, reading, ...   \n",
       "2    [nature, hiking, pets, religion, dogs, walking]   \n",
       "3              [sports, nba, Movies, Computer, beer]   \n",
       "4                                                 []   \n",
       "\n",
       "                      Profession  \\\n",
       "0          mathematics professor   \n",
       "1  database management professor   \n",
       "2                      Physician   \n",
       "3                        Student   \n",
       "4       Sport science researcher   \n",
       "\n",
       "                                         POI_answers  \n",
       "0  [Trattoria al Pompiere, Museo di Castelvecchio...  \n",
       "1  [Gelateria La Romana, Funicolare di Castel San...  \n",
       "2  [IAT Verona Centro, Museo Lapidario Maffeiano,...  \n",
       "3  [Parcheggio Arena (SABA), Stadio Marcantonio B...  \n",
       "4  [Gelateria La Romana, Funicolare di Castel San...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load CSV files\n",
    "poi_df = pd.read_csv(\"Datasets/poi_info_updated.csv\")\n",
    "descr_df = pd.read_csv(\"Datasets/data_descr_en_updated.csv\")\n",
    "users_df = pd.read_csv(\"Datasets/User Profiles_updated.csv\")\n",
    "\n",
    "# Parse JSON array cells into Python lists\n",
    "users_df[\"orcid__keywords\"] = users_df[\"orcid__keywords\"].apply(lambda x: json.loads(x) if isinstance(x, str) else [])\n",
    "users_df[\"previous_queries\"] = users_df[\"previous_queries\"].apply(lambda x: json.loads(x) if isinstance(x, str) else [])\n",
    "users_df[\"Personal Interest\"] = users_df[\"Personal Interest\"].apply(lambda x: json.loads(x) if isinstance(x, str) else [])\n",
    "users_df[\"POI_answers\"] = users_df[\"POI_answers\"].apply(lambda x: json.loads(x) if isinstance(x, str) else [])\n",
    "\n",
    "# Display dataset shapes and first few rows\n",
    "print(\"POI dataset shape:\", poi_df.shape)\n",
    "print(\"Descriptions dataset shape:\", descr_df.shape)\n",
    "display(poi_df.head())\n",
    "display(users_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bdc999",
   "metadata": {},
   "source": [
    "Merge the two datasets on common IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "2f4fd9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POIs with description available: 78\n"
     ]
    }
   ],
   "source": [
    "# Find common IDs between POI and descriptions\n",
    "common_ids = set(poi_df[\"poi_id\"]).intersection(set(descr_df[\"classref\"]))\n",
    "\n",
    "# Merge datasets on matching IDs\n",
    "merged_df = pd.merge(\n",
    "    poi_df[poi_df[\"poi_id\"].isin(common_ids)],\n",
    "    descr_df[descr_df[\"classref\"].isin(common_ids)],\n",
    "    left_on=\"poi_id\",\n",
    "    right_on=\"classref\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Keep only relevant columns\n",
    "merged_df = merged_df[[\n",
    "    \"poi_id\", \"poi_name\", \"category_name\", \"descr_trad_value\"\n",
    "]]\n",
    "\n",
    "# Show result\n",
    "print(f\"POIs with description available: {merged_df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "80d9a44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi_id</th>\n",
       "      <th>poi_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>descr_trad_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>Basilica di Santa Anastasia</td>\n",
       "      <td>Chiese</td>\n",
       "      <td>The church of St. Anastasia is a fine example ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>complesso del Duomo</td>\n",
       "      <td>Chiese</td>\n",
       "      <td>The Cathedral, which is dedicated to Santa Mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>Chiesa di San Bernardino</td>\n",
       "      <td>Chiese</td>\n",
       "      <td>The Church of San Bernardino is a Catholic pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>Chiesa di Santa Maria in Organo</td>\n",
       "      <td>Chiese</td>\n",
       "      <td>The church, near the Organo gate, already exis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>Chiesa di San Lorenzo</td>\n",
       "      <td>Chiese</td>\n",
       "      <td>San Lorenzo is a Romanesque Roman Catholic chu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>33</td>\n",
       "      <td>Multisala Rivoli</td>\n",
       "      <td>Cinema</td>\n",
       "      <td>A multi-screen cinema just off Piazza Bra, Riv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>34</td>\n",
       "      <td>Cinema Fiume</td>\n",
       "      <td>Cinema</td>\n",
       "      <td>Part of a local network of art-house and first...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>35</td>\n",
       "      <td>A.M.E.N</td>\n",
       "      <td>Discoteca</td>\n",
       "      <td>Set on the Torricelle hillside above the histo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>36</td>\n",
       "      <td>Berfi’s Club</td>\n",
       "      <td>Discoteca</td>\n",
       "      <td>A staple of Verona’s club scene for decades, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>37</td>\n",
       "      <td>LOVE (Disco Love Verona)</td>\n",
       "      <td>Discoteca</td>\n",
       "      <td>A contemporary nightclub in Verona, LOVE is lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    poi_id                         poi_name category_name  \\\n",
       "0       54      Basilica di Santa Anastasia        Chiese   \n",
       "1       52              complesso del Duomo        Chiese   \n",
       "2       70         Chiesa di San Bernardino        Chiese   \n",
       "3       74  Chiesa di Santa Maria in Organo        Chiese   \n",
       "4       51            Chiesa di San Lorenzo        Chiese   \n",
       "..     ...                              ...           ...   \n",
       "73      33                 Multisala Rivoli        Cinema   \n",
       "74      34                     Cinema Fiume        Cinema   \n",
       "75      35                          A.M.E.N     Discoteca   \n",
       "76      36                     Berfi’s Club     Discoteca   \n",
       "77      37         LOVE (Disco Love Verona)     Discoteca   \n",
       "\n",
       "                                     descr_trad_value  \n",
       "0   The church of St. Anastasia is a fine example ...  \n",
       "1   The Cathedral, which is dedicated to Santa Mar...  \n",
       "2   The Church of San Bernardino is a Catholic pla...  \n",
       "3   The church, near the Organo gate, already exis...  \n",
       "4   San Lorenzo is a Romanesque Roman Catholic chu...  \n",
       "..                                                ...  \n",
       "73  A multi-screen cinema just off Piazza Bra, Riv...  \n",
       "74  Part of a local network of art-house and first...  \n",
       "75  Set on the Torricelle hillside above the histo...  \n",
       "76  A staple of Verona’s club scene for decades, B...  \n",
       "77  A contemporary nightclub in Verona, LOVE is lo...  \n",
       "\n",
       "[78 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fea8476",
   "metadata": {},
   "source": [
    "# 2. Setup & small text utils \n",
    "\n",
    "This section sets up the storage paths for the personal knowledge base (memory stream and entity store, both saved as parquet files), loads the spaCy English model for entity recognition, and defines utility functions for:  \n",
    "\n",
    "- extracting named entities from text,  \n",
    "- loading and saving parquet files,  \n",
    "- resetting the memory and entity stores (full or partial reset).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "19239305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to store the personal knowledge base (parquet files)\n",
    "DATA_DIR = Path(\"data_store\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "MEM_PATH = DATA_DIR / \"memory_stream.parquet\"\n",
    "ENT_PATH = DATA_DIR / \"entity_store.parquet\"\n",
    "\n",
    "# Load English model for spaCy NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_entities(text: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Extract named entities using spaCy NER.\n",
    "    Filters out less useful types (dates, numbers, ordinals).\n",
    "    Returns a list of unique entity strings in lowercase.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "\n",
    "    doc = nlp(text)\n",
    "    entities = []\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        # ent.text = the actual entity string (e.g. \"Verona\")\n",
    "        # ent.label_ = the entity type (e.g. GPE, ORG, DATE)\n",
    "        if ent.label_ not in {\"DATE\", \"TIME\", \"CARDINAL\", \"ORDINAL\"}:\n",
    "            entities.append(ent.text.lower())\n",
    "\n",
    "    # Deduplicate by converting to set, then back to list\n",
    "    return list(set(entities))\n",
    "\n",
    "def _load_parquet(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load a parquet file if it exists; otherwise return an empty DataFrame.\"\"\"\n",
    "    if path.exists():\n",
    "        return pd.read_parquet(path)\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def _save_parquet(df: pd.DataFrame, path: Path):\n",
    "    \"\"\"Save DataFrame to parquet (creates/overwrites).\"\"\"\n",
    "    df.to_parquet(path, index=False)\n",
    "\n",
    "def reset_entity_store(full: bool = True):\n",
    "    \"\"\"\n",
    "    Reset both entity store and memory stream.\n",
    "    - full=True  -> delete ENT_PATH and MEM_PATH\n",
    "    - full=False -> delete only ENT_PATH\n",
    "    \"\"\"\n",
    "    ent_path = Path(ENT_PATH)\n",
    "    if ent_path.exists():\n",
    "        ent_path.unlink()\n",
    "        print(f\"[OK] Entity store {ent_path} deleted.\")\n",
    "    else:\n",
    "        print(f\"[INFO] Entity store {ent_path} already empty.\")\n",
    "\n",
    "    if full:\n",
    "        mem_path = Path(MEM_PATH)\n",
    "        if mem_path.exists():\n",
    "            mem_path.unlink()\n",
    "            print(f\"[OK] Memory stream {mem_path} deleted.\")\n",
    "        else:\n",
    "            print(f\"[INFO] Memory stream {mem_path} already empty.\")\n",
    "\n",
    "    # recreate empty DataFrames and save them\n",
    "    empty_ent = pd.DataFrame(columns=[\"user_id\",\"entity\",\"count\",\"first_seen\",\"last_seen\"])\n",
    "    _save_parquet(empty_ent, ENT_PATH)\n",
    "\n",
    "    #  keep only user_id, timestamp, text, meta (JSON)\n",
    "    empty_mem = pd.DataFrame(columns=[\"user_id\",\"timestamp\",\"text\",\"meta\"])\n",
    "    _save_parquet(empty_mem, MEM_PATH)\n",
    "\n",
    "    print(\"[DONE] Store succesfully resetted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2f5dc0",
   "metadata": {},
   "source": [
    "# 3. Memory Stream Construction\n",
    "\n",
    "This section defines the functions for constructing and populating the memory stream. \n",
    "It appends user interactions (queries, POI views, ORCID keywords) as timestamped events, storing both raw text and metadata.\n",
    "\n",
    "These records form the basis for building the entity-centric knowledge store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "6e584e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Memory stream appenders ===\n",
    "\n",
    "def append_memory(user_id: str,\n",
    "                  text: str,\n",
    "                  meta: dict | None = None,\n",
    "                  ts: datetime | None = None):\n",
    "    \"\"\"Append a single event to the memory stream.\"\"\"\n",
    "    \n",
    "    mem = _load_parquet(MEM_PATH)\n",
    "    row = {\n",
    "        \"user_id\": user_id,\n",
    "        \"timestamp\": pd.to_datetime(ts or datetime.now(timezone.utc)),\n",
    "        \"text\": text or \"\",\n",
    "        \"meta\": json.dumps(meta or {}, ensure_ascii=False),\n",
    "    }\n",
    "    mem = pd.concat([mem, pd.DataFrame([row])], ignore_index=True)\n",
    "    _save_parquet(mem, MEM_PATH)\n",
    "\n",
    "# === ORCID keyword extraction and insertion ===\n",
    "\n",
    "def extract_keywords_from_orcid(user, merged_df) -> list[str]:\n",
    "    \"\"\"Return keywords user profile + previous queries + POI answers.\"\"\"\n",
    "    \n",
    "    kws = []\n",
    "    orcid_keywords = user[\"orcid__keywords\"] if \"orcid__keywords\" in user else []\n",
    "    kws.extend([kw for kw in orcid_keywords if kw])\n",
    "\n",
    "    # Extract keywords from previous queries\n",
    "    previous_queries = user[\"previous_queries\"] if \"previous_queries\" in user else []\n",
    "    for query in previous_queries:\n",
    "        if query:\n",
    "            kws.extend(extract_entities(query))\n",
    "    \n",
    "    # Extract keywords from POI answers\n",
    "    poi_answers = user[\"POI_answers\"] if \"POI_answers\" in user else []\n",
    "    for answer in poi_answers:\n",
    "        if answer:\n",
    "            text = merged_df.loc[merged_df[\"poi_name\"] == answer, \"descr_trad_value\"]\n",
    "            kws.extend(extract_entities(str(text.item())))\n",
    "\n",
    "    return kws\n",
    "    \n",
    "def insert_orcid_keywords_to_memory(user_id, keywords) -> list[str]:\n",
    "    \"\"\"\n",
    "    Persist ORCID keywords into the memory stream without entity extraction.\n",
    "\n",
    "    Each keyword is saved as-is (after trimming), tagged with meta.src=\"orcid\".\n",
    "    Downstream, `rebuild_entity_store()` treats these entries as already-clean\n",
    "    entities and bypasses the linker.\n",
    "    \"\"\"\n",
    "    for term in keywords:\n",
    "        if isinstance(term, str) and term.strip():\n",
    "            append_memory(user_id=user_id, text=term.strip(), meta={\"src\": \"orcid\"})\n",
    "    return keywords\n",
    "\n",
    "\n",
    "def insert_previous_queries_and_POI_to_memory(user, merged_df) -> list[str]:\n",
    "    \"\"\"\n",
    "    Persist full-text previous queries and viewed-POI descriptions into memory.\n",
    "\n",
    "    For each user, this function:\n",
    "    Stores every previous query as full text with meta.src=\"query\".\n",
    "    Looks up each answered/viewed POI by name in `merged_df` and stores\n",
    "    its `descr_trad_value` (full text) with meta.src=\"poi\".\n",
    "    \n",
    "    \"\"\"\n",
    "    stored = []\n",
    "\n",
    "    # Previous queries (full text)\n",
    "    for q in user.get(\"previous_queries\", []):\n",
    "        if isinstance(q, str) and q.strip():\n",
    "            append_memory(user_id=user[\"user_id\"], text=q.strip(), meta={\"src\": \"query\"})\n",
    "            stored.append(q.strip())\n",
    "\n",
    "    # POI answers -> use the translated/clean description field\n",
    "    for ans in user.get(\"POI_answers\", []):\n",
    "        if ans:\n",
    "            ser = merged_df.loc[merged_df[\"poi_name\"] == ans, \"descr_trad_value\"]\n",
    "            if ser.empty:\n",
    "                continue\n",
    "            txt = str(ser.iloc[0]).strip()  # robust to multiple matches\n",
    "            if txt:\n",
    "                append_memory(user_id=user[\"user_id\"], text=txt, meta={\"src\": \"poi\"})\n",
    "                stored.append(txt)\n",
    "\n",
    "    return stored\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf16db3",
   "metadata": {},
   "source": [
    "## 4. Entity Store Construction\n",
    "\n",
    "This section rebuilds the entity store from the memory stream. \n",
    "\n",
    "Entities are extracted from user interactions, normalized (lowercased, spaces collapsed), and aggregated per user.  \n",
    "The resulting store tracks counts and first/last occurrence timestamps, enabling long-term personalization and keeping entities up to date over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "59b4c271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>entity</th>\n",
       "      <th>count</th>\n",
       "      <th>first_seen</th>\n",
       "      <th>last_seen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user_id, entity, count, first_seen, last_seen]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rebuild entity store from memory stream\n",
    "def rebuild_entity_store():\n",
    "    \"\"\"\n",
    "    Build the per-user entity store from the raw memory stream.\n",
    "\n",
    "    This function reads the event memory (MEM_PATH), where each row contains\n",
    "    a free-form text snippet and optional metadata, extracts entities per row,\n",
    "    and then prepares them for aggregation into a compact entity store with\n",
    "    counts and first/last seen timestamps per (user_id, entity).\n",
    "    \"\"\"\n",
    "    mem = _load_parquet(MEM_PATH)\n",
    "    if mem.empty:\n",
    "        ent = pd.DataFrame(columns=[\"user_id\", \"entity\", \"count\", \"first_seen\", \"last_seen\"])\n",
    "        _save_parquet(ent, ENT_PATH)\n",
    "        return\n",
    "\n",
    "    # Normalize timestamp and text columns\n",
    "    mem[\"timestamp\"] = pd.to_datetime(mem[\"timestamp\"], utc=True, errors=\"coerce\")\n",
    "    mem[\"text\"] = mem[\"text\"].astype(str)\n",
    "\n",
    "    # Extract a lightweight source tag from the JSON `meta` (if present)\n",
    "    def _get_src(m):\n",
    "        try:\n",
    "            d = json.loads(m) if isinstance(m, str) else (m or {})\n",
    "            return d.get(\"src\", None)\n",
    "        except Exception:\n",
    "            return None\n",
    "    mem[\"src\"] = mem[\"meta\"].apply(_get_src)\n",
    "\n",
    "    # Normalize text: lowercase, collapse spaces\n",
    "    def _norm(s: str) -> str:\n",
    "        return \" \".join(s.lower().split())\n",
    "\n",
    "    # # Row-wise entity extraction with an ORCID-specific fast path\n",
    "    def _extract_row(r) -> list[str]:\n",
    "        t = r[\"text\"].strip()\n",
    "        if not t:\n",
    "            return []\n",
    "        if r[\"src\"] == \"orcid\":\n",
    "            # Trust ORCID keywords as already curated; store as a single normalized token\n",
    "            return [_norm(t)]\n",
    "        ents = extract_entities(t)\n",
    "        return [_norm(e) for e in ents if isinstance(e, str) and e.strip()]\n",
    "\n",
    "    mem[\"ents\"] = mem.apply(_extract_row, axis=1)\n",
    "\n",
    "    # flatten\n",
    "    df = mem[[\"user_id\", \"timestamp\", \"ents\"]].explode(\"ents\", ignore_index=True)\n",
    "    df = df.dropna(subset=[\"ents\"]).rename(columns={\"ents\": \"entity\"})\n",
    "\n",
    "    # Aggregate counts and first/last seen\n",
    "    ent = (df.groupby([\"user_id\", \"entity\"], dropna=False)\n",
    "             .agg(count=(\"entity\", \"size\"),\n",
    "                  first_seen=(\"timestamp\", \"min\"),\n",
    "                  last_seen=(\"timestamp\", \"max\"))\n",
    "             .reset_index())\n",
    "\n",
    "    ent = (ent.sort_values([\"user_id\", \"entity\", \"last_seen\"])\n",
    "             .drop_duplicates([\"user_id\", \"entity\"], keep=\"last\"))\n",
    "\n",
    "    _save_parquet(ent, ENT_PATH)\n",
    "\n",
    "\n",
    "ent = pd.read_parquet(ENT_PATH)\n",
    "display(ent.head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ec105e",
   "metadata": {},
   "source": [
    "## 5. User & Session Modeling\n",
    "\n",
    "\n",
    "This section models user behavior through a memory stream of logged events, including queries and POI page views.\n",
    "\n",
    "The utilities defined here enable capturing recent interactions to build a session context that complements long-term profiles for personalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4894f901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Logging helpers for queries and pages ===\n",
    "\n",
    "def log_query_event(current_query: str, user_id: str):\n",
    "    \"\"\"Append a user query into the memory stream.\"\"\"\n",
    "    append_memory(user_id=user_id, text=current_query.strip(), meta={\"src\": \"query\"})\n",
    "\n",
    "def log_page_viewed_event(poi_row: pd.Series, user_id: str):\n",
    "    \"\"\"\n",
    "    Append a 'page view' using your merged_df row.\n",
    "    We concatenate name, category, and description into the 'text' field.\n",
    "    \"\"\"\n",
    "    text = f\"{poi_row['descr_trad_value']}\"\n",
    "    append_memory(user_id=user_id, text=text, meta={\"src\": \"poi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af55a65a",
   "metadata": {},
   "source": [
    "## 6. Pick K_entities from session history and context\n",
    "\n",
    "This section selects up to *k* personal entities from the current context, where context entities are extracted from the current query and page text.\n",
    "  \n",
    "It supports three K-LaMP strategies—**familiar** (probability ∝ past counts), **unfamiliar** (probability ∝ 1/(count+1), includes unseen), and **lapsed** (previously seen but not recently)—using weighted sampling without replacement to balance relevance and novelty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "e1d6dd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Retrieve personal entities for the current context ===\n",
    "\n",
    "def pick_personal_entities_k_lamp(user_id: str,\n",
    "                         query: str,\n",
    "                         page_text: str,\n",
    "                         strategy: str = \"familiar\",   # \"familiar\" | \"unfamiliar\" | \"lapsed\"\n",
    "                         k: int = 5,\n",
    "                         lapsed_days: int = 14,\n",
    "                         seed: int | None = None) -> List[str]:\n",
    "    \"\"\"\n",
    "    K-LaMP selection:\n",
    "      - Context entities = entities(query) ∪ entities(page)\n",
    "      - Look up (count, last_seen) in user's entity store\n",
    "      - Sample k entities according to strategy:\n",
    "          familiar:     sample ∝ count (exclude count==0)\n",
    "          unfamiliar:   sample ∝ 1/(count+1)  (include unseen with high prob)\n",
    "          lapsed:       keep last_seen < now-14d, sample ∝ count\n",
    "    Sampling is WITHOUT replacement. Use `seed` for reproducibility.\n",
    "    \"\"\"\n",
    "    # context entities (order-preserving unique, canonicalized)\n",
    "    ctx_raw = (extract_entities(query) or []) + (extract_entities(page_text) or [])\n",
    "    ctx = []\n",
    "    for e in ctx_raw:\n",
    "        ce = \" \".join((e or \"\").lower().split())\n",
    "        if ce and ce not in ctx:\n",
    "            ctx.append(ce)\n",
    "    if not ctx:\n",
    "        return []\n",
    "\n",
    "    # user store lookup\n",
    "    ent = _load_parquet(ENT_PATH)\n",
    "    if ent.empty:\n",
    "        ent_user = pd.DataFrame(columns=[\"entity\",\"count\",\"last_seen\"])\n",
    "    else:\n",
    "        ent_user = ent[ent[\"user_id\"] == user_id].copy()\n",
    "        # canonicalize entity and ensure datetime\n",
    "        ent_user[\"entity\"] = ent_user[\"entity\"].astype(str).str.lower().str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "        ent_user[\"last_seen\"] = pd.to_datetime(ent_user[\"last_seen\"], utc=True, errors=\"coerce\")\n",
    "        # keep latest row per entity if duplicates exist\n",
    "        ent_user = (ent_user.sort_values([\"entity\",\"last_seen\"])\n",
    "                             .drop_duplicates(subset=[\"entity\"], keep=\"last\"))\n",
    "\n",
    "    ent_user.set_index(\"entity\", inplace=True, drop=False)\n",
    "\n",
    "    now = datetime.now(timezone.utc)\n",
    "    cutoff = now - timedelta(days=lapsed_days)\n",
    "\n",
    "    items = []  # (entity, count, last_seen)\n",
    "    for e in ctx:\n",
    "        if e in ent_user.index:   # check if entity exists in user's store\n",
    "            row = ent_user.loc[e]\n",
    "            # if multiple rows (edge case), take the last one\n",
    "            if isinstance(row, pd.DataFrame):\n",
    "                row = row.sort_values(\"last_seen\").iloc[-1]\n",
    "            cnt = int(pd.to_numeric(row.get(\"count\", 0), errors=\"coerce\") or 0)\n",
    "            last_seen = pd.to_datetime(row.get(\"last_seen\"), utc=True, errors=\"coerce\")\n",
    "        else:\n",
    "            cnt = 0\n",
    "            last_seen = None\n",
    "        items.append((e, cnt, last_seen))\n",
    "\n",
    "    # candidates + weights\n",
    "    if strategy == \"familiar\":\n",
    "        cand = [(e, c, ls) for (e, c, ls) in items if c > 0]\n",
    "        weights = [float(c) for (_, c, _) in cand]  # ∝ count\n",
    "\n",
    "    elif strategy == \"unfamiliar\":\n",
    "        cand = items[:]  # include unseen\n",
    "        weights = [1.0 / (c + 1.0) for (_, c, _) in cand]  # ∝ 1/(count+1)\n",
    "\n",
    "    elif strategy == \"lapsed\":\n",
    "        cand = [(e, c, ls) for (e, c, ls) in items if (ls is not None and pd.notna(ls) and ls < cutoff)]\n",
    "        weights = [float(c) for (_, c, _) in cand]  # ∝ count\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"strategy must be 'familiar', 'unfamiliar', or 'lapsed'\")\n",
    "\n",
    "    if not cand:  # if no candidates after filtering\n",
    "        return []\n",
    "\n",
    "    if sum(weights) <= 0:\n",
    "        weights = [1.0] * len(cand)  # fallback uniform\n",
    "\n",
    "    # weighted sampling without replacement\n",
    "    rng = random.Random(seed)\n",
    "    chosen: List[str] = []\n",
    "    cand_e = [e for (e, _, _) in cand]  # candidate entities\n",
    "    cand_w = [float(w) for w in weights]  # candidate weights\n",
    "\n",
    "    for _ in range(min(k, len(cand_e))):\n",
    "        total = sum(cand_w)\n",
    "        if total <= 0:\n",
    "            idx = rng.randrange(len(cand_e))\n",
    "        else:\n",
    "            r = rng.random() * total\n",
    "            acc = 0.0\n",
    "            idx = 0\n",
    "            for i, w in enumerate(cand_w):\n",
    "                acc += w\n",
    "                if r <= acc:\n",
    "                    idx = i\n",
    "                    break\n",
    "        chosen.append(cand_e.pop(idx))\n",
    "        cand_w.pop(idx)\n",
    "\n",
    "    return chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ff5fe6",
   "metadata": {},
   "source": [
    "## 7. Prompt Builder for Gemini K LaMP style\n",
    "\n",
    "This section implements utilities to build prompts for Gemini in line with the K-LaMP framework.  \n",
    "\n",
    "It reconstructs the user’s session (queries, viewed pages) and combines it with personal entities to form structured **system** and **user** messages, ensuring that query suggestions are contextual, personalized, and aligned with long-term interests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "c90b8ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Prompt builder for Gemini ===\n",
    "\n",
    "def _load_memory() -> pd.DataFrame:\n",
    "    \"\"\"Load memory stream with a stable schema (no 'source' column).\"\"\"\n",
    "    expected = [\"user_id\", \"timestamp\", \"text\", \"meta\"]\n",
    "    mem = _load_parquet(MEM_PATH)\n",
    "    for c in expected:\n",
    "        if c not in mem.columns:\n",
    "            mem[c] = pd.Series(dtype=\"object\")\n",
    "    mem[\"timestamp\"] = pd.to_datetime(mem[\"timestamp\"], utc=True, errors=\"coerce\")\n",
    "    return mem[expected]\n",
    "\n",
    "def _get_src(meta_val):\n",
    "    \"\"\"Extract 'src' from JSON-encoded meta field.\"\"\"\n",
    "    try:\n",
    "        d = json.loads(meta_val) if isinstance(meta_val, str) else (meta_val or {})\n",
    "        return d.get(\"src\", None)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "def get_session_queries(\n",
    "    user_id: str,\n",
    "    n: int | None = None,\n",
    "    hours: int | None = None,\n",
    "    order: str = \"desc\"\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Return the user's session queries where meta['src'] == 'query'.\n",
    "    - n: If set, limits the number of returned queries.\n",
    "    - hours: If set, only include rows with timestamp >= now(UTC) - hours\n",
    "    - order: Sort direction of the final output: 'asc' or 'desc'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Early exit if a non-positive n is provided\n",
    "    if n is not None and n <= 0:\n",
    "        return []\n",
    "\n",
    "    mem = _load_memory()\n",
    "\n",
    "    # Derive the 'src' field from 'meta' without mutating the original DataFrame in place\n",
    "    src = mem[\"meta\"].apply(_get_src)\n",
    "    # Keep only rows for the target user and where src == 'query'\n",
    "    q = mem[(mem[\"user_id\"] == user_id) & (src == \"query\")].copy()\n",
    "\n",
    "    # Optional time filter: keep only entries newer than the cutoff\n",
    "    if hours is not None:\n",
    "        cutoff = datetime.now(timezone.utc) - timedelta(hours=hours)\n",
    "        q = q[q[\"timestamp\"] >= cutoff]\n",
    "\n",
    "    # Normalize and validate the sort order\n",
    "    order = (order or \"desc\").lower()\n",
    "    if order not in (\"asc\", \"desc\"):\n",
    "        order = \"desc\"\n",
    "\n",
    "    # If n is requested, preselect exactly n rows using efficient selectors\n",
    "    # This avoids a full sort on large DataFrames\n",
    "    if n is not None:\n",
    "        # For 'asc' we want the n oldest; for 'desc' the n most recent\n",
    "        q = q.nsmallest(n, \"timestamp\") if order == \"asc\" else q.nlargest(n, \"timestamp\")\n",
    "\n",
    "    # Final presentation order as requested by the caller\n",
    "    q = q.sort_values(\"timestamp\", ascending=(order == \"asc\"))\n",
    "\n",
    "    # Extract query texts, dropping NaNs and ensuring str type\n",
    "    queries = q[\"text\"].dropna().astype(str).tolist()\n",
    "    return queries\n",
    "\n",
    "def get_latest_article(user_id: str) -> tuple[str, str]:\n",
    "    \"\"\"Return (title, text) of the most recent POI/page event (meta['src'] == 'poi').\"\"\"\n",
    "    mem = _load_memory()\n",
    "    mem[\"src\"] = mem[\"meta\"].apply(_get_src)\n",
    "\n",
    "    pages = mem[(mem[\"user_id\"] == user_id) & (mem[\"src\"] == \"poi\")].copy()\n",
    "    if pages.empty:\n",
    "        return \"\", \"\"\n",
    "\n",
    "    r = pages.sort_values(\"timestamp\", ascending=False).iloc[0]\n",
    "    try:\n",
    "        meta = json.loads(r[\"meta\"] or \"{}\")\n",
    "    except Exception:\n",
    "        meta = {}\n",
    "    title = meta.get(\"poi_name\") or (str(r[\"text\"]).split(\":\")[0][:120] if isinstance(r[\"text\"], str) else \"\")\n",
    "    text = str(r[\"text\"] or \"\")\n",
    "    return title, text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b939466",
   "metadata": {},
   "source": [
    "**Prompt for K-LaMP (paper-style) + ORCID**\n",
    "\n",
    "This section follows the K-LaMP design while also including long-term ORCID keywords. \n",
    "It composes structured **system** and **user** messages that combine:  \n",
    "- the current query,  \n",
    "- the recent session history,  \n",
    "- the current article (title + text),  \n",
    "- sampled personal entities from the knowledge store,  \n",
    "- long-term ORCID keywords.  \n",
    "\n",
    "The output is a prompt dictionary `{system, user}` to be used with the Gemini model for next-query generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c41a8376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_lamp_paper_prompt_weighted(user_row: dict | pd.Series,\n",
    "                                     current_query: str,\n",
    "                                     page_title: str,\n",
    "                                     page_text: str,\n",
    "                                     strategy: str = \"familiar\",\n",
    "                                     k_entities: int = 5,\n",
    "                                     personal_keywords: list[str] | None = None,\n",
    "                                     n_session: int | None = None,     # None -> all queries\n",
    "                                     max_article_chars: int = 1200) -> dict:\n",
    "    \"\"\"\n",
    "    Build {system,user} messages as in K-LaMP, with 'Personal Entities' = entities\n",
    "    sampled from the current context [query · page] according to `strategy`.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(user_row, pd.Series):\n",
    "        user_row = user_row.to_dict()\n",
    "    user_id = user_row[\"user_id\"]\n",
    "\n",
    "    # System message (rules)\n",
    "    system_msg = (\n",
    "        \"You are an AI assistant whose primary goal is to suggest a next search query, in order to help a user search and find information better on the search engine.\"\n",
    "        \" Two different queries and entities are separated by the token '|'. For example,'Microsoft' and 'Google' would appear as 'Microsoft' | 'Google'.\\n\"\n",
    "    )\n",
    "\n",
    "    # Session (last N or all)\n",
    "    session_list = get_session_queries(user_id=user_id, n=n_session, order=\"desc\")\n",
    "    session_str = \" | \".join(session_list or [])\n",
    "\n",
    "    # Article\n",
    "    art_title = page_title or \"\"\n",
    "    art_text = (page_text or \"\")[:max_article_chars]\n",
    "\n",
    "    # Personal Entities via K-LaMP sampler (context-dependent)\n",
    "    personal_ents = pick_personal_entities_k_lamp(\n",
    "        user_id=user_id,\n",
    "        query=current_query,\n",
    "        page_text=page_text,\n",
    "        strategy=strategy,\n",
    "        lapsed_days=14,\n",
    "        k=k_entities,\n",
    "        seed=42,  # optional reproducibility\n",
    "    )\n",
    "    personal_str = \" | \".join(personal_ents)\n",
    "\n",
    "    # Personal Keywords (static, e.g., ORCID)\n",
    "    personal_keywords_str = \" | \".join(personal_keywords or [])\n",
    "\n",
    "    # User message (payload)\n",
    "    user_msg = (\n",
    "        \"You are going to suggest ONE next search query based on the current query, the current session, \"\n",
    "        \"the current article, the user's personal entities, and the user's ORCID keywords.\\n\\n\"\n",
    "\n",
    "        \"Guidance and priorities:\\n\"\n",
    "        \"- Prioritize long-term user relevance from ORCID keywords (≈50%).\\n\"\n",
    "        \"- Maintain session intent continuity without lexical repetition (≈25%).\\n\"\n",
    "        \"- Use the article only as supporting context (cap ≈25%).\\n\"\n",
    "        \"- Favor novelty and depth over logistics unless the session explicitly shows planning intent.\\n\"\n",
    "        #\"- ORCID Keywords have higher priority than Personal Entities; use entities only as complementary, short-term signals.\\n\\n\"\n",
    "        #\"- Mantain the next query concise (under 8 words)\\n\\n\"\n",
    "\n",
    "        \"Definitions:\\n\"\n",
    "        \"- The query is a specific set of phrases that the user enters into the search engine to find the information or resources related to a particular topic, question, or interest.\\n\"\n",
    "        \"- The session refers to a sequence of queries requested by the user on the search engine, within a certain period of time or with regard to the completion of a task.\\n\"\n",
    "        \"- The article refers to a specific webpage that the user clicks and reads from several search results displayed by the search engine in response to the requested query.\\n\"\n",
    "        \"- The personal entity refers to a topic, keyword, person, event, or any subject that is specifically relevant or appealing to the individual user based on their personal interests.\\n\"\n",
    "        \"- The ORCID keywords refer to self-declared research topics and academic interests from the user's ORCID profile. They provide a stable signal of long-term expertise or focus areas, complementing the personal entities extracted from recent interactions.\\n\\n\"\n",
    "\n",
    "        \"Read the following query, session, article, and personal entities of the user as the context information, which might be helpful and relevant to suggest the next query.\\n\\n\"\n",
    "        f\"Query: {current_query}\\n\"\n",
    "        f\"Session: {session_str}\\n\"\n",
    "        f\"Article Title: {art_title}\\n\"\n",
    "        f\"Article Text: {art_text}\\n\\n\"\n",
    "        f\"Personal Entities: {personal_str}\\n\\n\"\n",
    "        f\"ORCID Keywords: {personal_keywords_str}\\n\\n\"\n",
    "        \"Based on the above query, session, article, personal entities, and ORCID keywords, please generate one next query suggestion with the \"\n",
    "        \"rationale, in the format of\\n\"\n",
    "        \"Query Suggestion:\\n\"\n",
    "        \"Rationale:\"\n",
    "    )\n",
    "    return {\"system\": system_msg, \"user\": user_msg}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f685c060",
   "metadata": {},
   "source": [
    "**Prompt for Enhanced K-LaMP with Profile Integration**\n",
    "\n",
    "Extends the original K-LaMP prompt builder by integrating **user profile attributes** (profession, nationality, personal interests) together with **ORCID keywords** and context-dependent personal entities.  \n",
    "\n",
    "The system and user messages are designed to:  \n",
    "- prioritize long-term signals from ORCID and professional persona,  \n",
    "- maintain session continuity,  \n",
    "- use the current article as supporting context,  \n",
    "- and generate personalized next-query suggestions that balance both short-term and long-term relevance.  \n",
    "\n",
    "\n",
    "This enhanced formulation aims to stress-test whether integrating explicit profile metadata improves personalization beyond entity-based signals alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "61f0772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_lamp_prompt_enhanced(user_row: dict | pd.Series,\n",
    "                                     current_query: str,\n",
    "                                     page_title: str,\n",
    "                                     page_text: str,\n",
    "                                     strategy: str = \"familiar\",\n",
    "                                     k_entities: int = 5,\n",
    "                                     personal_keywords: list[str] | None = None,\n",
    "                                     n_session: int | None = None,     # None -> all queries\n",
    "                                     max_article_chars: int = 1200) -> dict:\n",
    "    \"\"\"\n",
    "    Build {system,user} messages as in K-LaMP, with 'Personal Entities' = entities\n",
    "    sampled from the current context [query · page] according to `strategy`.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(user_row, pd.Series):\n",
    "        user_row = user_row.to_dict()\n",
    "    user_id = user_row[\"user_id\"]\n",
    "\n",
    "    # System message (rules)\n",
    "    system_msg = (\n",
    "        \"You are an AI assistant whose primary goal is to suggest a next search query, \"\n",
    "        \"to help the user search and find information better on the search engine. \"\n",
    "        \"Different queries and entities are separated by '|'.\"\n",
    "    )\n",
    "\n",
    "    # Session (last N or all)\n",
    "    session_list = get_session_queries(user_id=user_id, n=n_session, order=\"desc\")\n",
    "    session_str = \" | \".join(session_list or [])\n",
    "\n",
    "    # Article\n",
    "    art_title = page_title or \"\"\n",
    "    art_text = (page_text or \"\")[:max_article_chars]\n",
    "\n",
    "    # Personal Entities via K-LaMP sampler (context-dependent)\n",
    "    personal_ents = pick_personal_entities_k_lamp(\n",
    "        user_id=user_id,\n",
    "        query=current_query,\n",
    "        page_text=page_text,\n",
    "        strategy=strategy,\n",
    "        lapsed_days=14,\n",
    "        k=k_entities,\n",
    "        seed=42,  # optional reproducibility\n",
    "    )\n",
    "    personal_str = \" | \".join(personal_ents)\n",
    "\n",
    "    # Personal Keywords (static, e.g., ORCID)\n",
    "    personal_keywords_str = \" | \".join(personal_keywords or [])\n",
    "\n",
    "    # Personal interests\n",
    "    personal_interests_str = \" | \".join(user_row.get(\"Personal Interest\", []))\n",
    "\n",
    "    # User message (payload)\n",
    "    user_msg = (\n",
    "        \"You are going to suggest ONE next search query based on the current query, the current session, \"\n",
    "        \"the current article, the user's personal entities, and the user's ORCID keywords.\\n\\n\"\n",
    "\n",
    "        \"Guidance and priorities:\\n\"\n",
    "        \"- Prioritize long-term user relevance from ORCID keywords and profession/persona (≈50%).\\n\"\n",
    "        \"- Maintain session intent continuity without lexical repetition (≈25%).\\n\"\n",
    "        \"- Use the article only as supporting context (cap ≈25%).\\n\"\n",
    "        \"- Favor novelty and depth over logistics unless the session explicitly shows planning intent.\\n\"\n",
    "        \"- ORCID Keywords have higher priority than Personal Entities; use entities only as complementary, short-term signals.\\n\\n\"\n",
    "        \"- Mantain the next query concise (under 6 words)\\n\\n\"\n",
    "        #\"- Always ensure the next query is a natural continuation of the clicked article. If the article is a venue (e.g., restaurant, gelateria, shop), the next query must logically involve details such as reviews, opening hours, similar venues, or cultural context. \"\n",
    "        #\"- Weigh the importance of article, session, and ORCID profile dynamically.\"\"\n",
    "        #\"- If the article is strongly aligned with the ORCID profile, integrate both.\"\"\n",
    "        #\"- If the article is unrelated, prefer session continuity over ORCID.\"\"\n",
    "        #\"- Always avoid suggestions that feel unnatural compared to the clicked article.\"\n",
    "\n",
    "        \"Explanations:\\n\"\n",
    "        \"- Query: the phrase the user types next.\\n\"\n",
    "        \"- Session: the recent sequence of queries tied to the same task.\\n\"\n",
    "        \"- Article: the page the user just read/clicked.\\n\"\n",
    "        \"- Personal Entities: short-term topics/entities extracted from recent user context.\\n\"\n",
    "        \"- ORCID Keywords: self-declared, long-term academic/professional interests from the user's ORCID profile; \"\n",
    "        \"they should steer personalization beyond the current article.\\n\\n\"\n",
    "\n",
    "        \"CONTEXT:\\n\"\n",
    "        f\"Query: {current_query}\\n\"\n",
    "        f\"Session:{session_str}\\n\"\n",
    "        f\"Article Title: {art_title}\\n\"\n",
    "        f\"Article Text: {art_text}\\n\\n\"\n",
    "        f\"Personal Entities: {personal_str}\\n\\n\"\n",
    "        f\"User personal interests: {personal_interests_str}\\n\"\n",
    "        f\"User profession: {user_row.get('Profession')}\\n\"\n",
    "        f\"User nationality: {user_row.get('nationality')}\\n\"\n",
    "        f\"ORCID Keywords: {personal_keywords_str}\\n\\n\"\n",
    "\n",
    "\n",
    "        \"Based on the above query, session, article, user context entities, user profile keywords, and the user characteristics please generate one next query \"\n",
    "        \"suggestion with the rationale, in the format of\\n\"\n",
    "        \"Query Suggestion:\\n\"\n",
    "        \"Rationale:\"\n",
    "    )\n",
    "    return {\"system\": system_msg, \"user\": user_msg}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd04ae64",
   "metadata": {},
   "source": [
    "## 8. Gemini API Setup\n",
    "\n",
    "This section sets up access to the Gemini API.\n",
    "\n",
    "The API key is loaded securely from environment variables, and the latest chat-style Gemini model is initialized for use in query generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a9576580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Gemini model setup ===\n",
    "\n",
    "# Simple sanity check for the API key\n",
    "if not os.getenv(\"GEMINI_API_KEY\"):\n",
    "    print(\"[WARN] GEMINI_API_KEY is not set; Gemini calls will fail.\")\n",
    "\n",
    "# Use the API key from environment variable\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "# Load Gemini model (chat-style)\n",
    "model = genai.GenerativeModel(model_name=\"models/gemini-1.5-pro-latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d4d033",
   "metadata": {},
   "source": [
    "## 9. User Initialization and Session Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bafab9",
   "metadata": {},
   "source": [
    "**9.1 Populate memory with profiles**\n",
    "\n",
    "This subsection initializes the user profiles (u1–u4) from the dataset and logs their ORCID keywords, previous queries, and POI descriptions into the memory stream.  \n",
    "\n",
    "After populating the stream, the entity store is rebuilt to incorporate these signals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "50b5bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset_entity_store(full=True)  # Reset both entity store and memory stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "a7afe96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feder\\AppData\\Local\\Temp\\ipykernel_59036\\376493135.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  mem = pd.concat([mem, pd.DataFrame([row])], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>entity</th>\n",
       "      <th>count</th>\n",
       "      <th>first_seen</th>\n",
       "      <th>last_seen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u1</td>\n",
       "      <td>adige</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-09-23 12:32:11.475279+00:00</td>\n",
       "      <td>2025-09-23 12:32:11.482624+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u1</td>\n",
       "      <td>allied</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-09-23 12:32:11.475279+00:00</td>\n",
       "      <td>2025-09-23 12:32:11.475279+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u1</td>\n",
       "      <td>amedeo mantellato</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-09-23 12:32:11.475279+00:00</td>\n",
       "      <td>2025-09-23 12:32:11.475279+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u1</td>\n",
       "      <td>arena</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-09-23 12:32:11.391330+00:00</td>\n",
       "      <td>2025-09-23 12:32:11.493494+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u1</td>\n",
       "      <td>austrian</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-09-23 12:32:11.449725+00:00</td>\n",
       "      <td>2025-09-23 12:32:11.449725+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>u5</td>\n",
       "      <td>verona villafranca airport</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-09-23 12:32:12.408344+00:00</td>\n",
       "      <td>2025-09-23 12:32:12.408344+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>u5</td>\n",
       "      <td>verona villafranca s.p.a.</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-09-23 12:32:12.408344+00:00</td>\n",
       "      <td>2025-09-23 12:32:12.408344+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>u5</td>\n",
       "      <td>veronese</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-09-23 12:32:12.426038+00:00</td>\n",
       "      <td>2025-09-23 12:32:12.426038+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>u5</td>\n",
       "      <td>vicenza</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-09-23 12:32:12.408344+00:00</td>\n",
       "      <td>2025-09-23 12:32:12.408344+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>u5</td>\n",
       "      <td>villafranca</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-09-23 12:32:12.408344+00:00</td>\n",
       "      <td>2025-09-23 12:32:12.408344+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>386 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id                      entity  count  \\\n",
       "0        u1                       adige      2   \n",
       "1        u1                      allied      1   \n",
       "2        u1           amedeo mantellato      1   \n",
       "3        u1                       arena      2   \n",
       "4        u1                    austrian      1   \n",
       "..      ...                         ...    ...   \n",
       "381      u5  verona villafranca airport      1   \n",
       "382      u5   verona villafranca s.p.a.      1   \n",
       "383      u5                    veronese      1   \n",
       "384      u5                     vicenza      1   \n",
       "385      u5                 villafranca      1   \n",
       "\n",
       "                          first_seen                        last_seen  \n",
       "0   2025-09-23 12:32:11.475279+00:00 2025-09-23 12:32:11.482624+00:00  \n",
       "1   2025-09-23 12:32:11.475279+00:00 2025-09-23 12:32:11.475279+00:00  \n",
       "2   2025-09-23 12:32:11.475279+00:00 2025-09-23 12:32:11.475279+00:00  \n",
       "3   2025-09-23 12:32:11.391330+00:00 2025-09-23 12:32:11.493494+00:00  \n",
       "4   2025-09-23 12:32:11.449725+00:00 2025-09-23 12:32:11.449725+00:00  \n",
       "..                               ...                              ...  \n",
       "381 2025-09-23 12:32:12.408344+00:00 2025-09-23 12:32:12.408344+00:00  \n",
       "382 2025-09-23 12:32:12.408344+00:00 2025-09-23 12:32:12.408344+00:00  \n",
       "383 2025-09-23 12:32:12.426038+00:00 2025-09-23 12:32:12.426038+00:00  \n",
       "384 2025-09-23 12:32:12.408344+00:00 2025-09-23 12:32:12.408344+00:00  \n",
       "385 2025-09-23 12:32:12.408344+00:00 2025-09-23 12:32:12.408344+00:00  \n",
       "\n",
       "[386 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set user_id as index for easy access\n",
    "users_df = users_df.set_index(\"user_id\", drop=False)\n",
    "\n",
    "u1 = users_df.loc[\"u1\"]\n",
    "u2 = users_df.loc[\"u2\"]\n",
    "u3 = users_df.loc[\"u3\"]\n",
    "u4 = users_df.loc[\"u4\"]\n",
    "u5 = users_df.loc[\"u5\"]\n",
    "\n",
    "# Save for each user the ORCID keywords, previous queries + POI descriptions in the memory stream\n",
    "for user in [u1, u2, u3, u4,u5]:\n",
    "    insert_orcid_keywords_to_memory(user.user_id, user.orcid__keywords)\n",
    "    insert_previous_queries_and_POI_to_memory(user, merged_df)\n",
    "\n",
    "rebuild_entity_store()\n",
    "ent = pd.read_parquet(ENT_PATH)\n",
    "display(ent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575e4eb4",
   "metadata": {},
   "source": [
    "**9.2 Simulate session logging**\n",
    "\n",
    "\n",
    "This subsection simulates a user session by logging a new query and a POI page view for each user.\n",
    "\n",
    "The entity store is then rebuilt, and the article context (title and description) is prepared for prompt construction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "86cf72b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gelateria La Romana'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Gelateria La Romana (Ristorazione): Part of the La Romana artisanal chain, the Verona branch opened in 2013 on Piazza Santo Spirito 9. It pairs gelato made with a franchise-wide focus on ingredients with pastries and café service, offering both classic Italian flavors and rotating specials. Seating '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose a current query and a visited page\n",
    "current_query = \"Best ice cream in Verona?\"\n",
    "poi_row = merged_df.iloc[62] \n",
    "\n",
    "# Log to memory\n",
    "for user in [u1, u2, u3, u4, u5]:\n",
    "    log_query_event(current_query, user.user_id)\n",
    "    log_page_viewed_event(poi_row, user.user_id)\n",
    "\n",
    "#  Rebuild entity store\n",
    "rebuild_entity_store()\n",
    "\n",
    "# Build page title/text\n",
    "page_title = poi_row[\"poi_name\"]\n",
    "page_text  = f\"{poi_row['poi_name']} ({poi_row['category_name']}): {poi_row['descr_trad_value']}\"\n",
    "display(page_title, page_text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e51c0a9",
   "metadata": {},
   "source": [
    "## 10. Next Query Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0133fc4",
   "metadata": {},
   "source": [
    "**10.1 Paper Scenario (Original K-LaMP)**\n",
    "\n",
    "This subsection reproduces the original K-LaMP setup with modified prompt of the LLM in order to focus more on ORCID keywords and give more personalization to the user.  \n",
    "For each sample user, it builds the **paper-style prompt**, displays the full *system* and *user* messages, invokes Gemini to generate **one next search query**, and outputs the suggested query for inspection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c580c56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************************************\n",
      "=== NEXT QUERY GENERATION WITH K-LAMP PROMPT-WEIGHTED to focus on ORCID ===\n",
      "\n",
      "\u001b[36m=== USER u1 - mathematics professor ===\u001b[0m\n",
      "\n",
      "=== SYSTEM ===\n",
      "\n",
      "You are an AI assistant whose primary goal is to suggest a next search query, in order to help a user search and find information better on the search engine. Two different queries and entities are separated by the token '|'. For example,'Microsoft' and 'Google' would appear as 'Microsoft' | 'Google'.\n",
      "\n",
      "=== USER ===\n",
      "\n",
      "You are going to suggest ONE next search query based on the current query, the current session, the current article, the user's personal entities, and the user's ORCID keywords.\n",
      "\n",
      "Guidance and priorities:\n",
      "- Prioritize long-term user relevance from ORCID keywords (≈50%).\n",
      "- Maintain session intent continuity without lexical repetition (≈25%).\n",
      "- Use the article only as supporting context (cap ≈25%).\n",
      "- Favor novelty and depth over logistics unless the session explicitly shows planning intent.\n",
      "Definitions:\n",
      "- The query is a specific set of phrases that the user enters into the search engine to find the information or resources related to a particular topic, question, or interest.\n",
      "- The session refers to a sequence of queries requested by the user on the search engine, within a certain period of time or with regard to the completion of a task.\n",
      "- The article refers to a specific webpage that the user clicks and reads from several search results displayed by the search engine in response to the requested query.\n",
      "- The personal entity refers to a topic, keyword, person, event, or any subject that is specifically relevant or appealing to the individual user based on their personal interests.\n",
      "- The ORCID keywords refer to self-declared research topics and academic interests from the user's ORCID profile. They provide a stable signal of long-term expertise or focus areas, complementing the personal entities extracted from recent interactions.\n",
      "\n",
      "Read the following query, session, article, and personal entities of the user as the context information, which might be helpful and relevant to suggest the next query.\n",
      "\n",
      "Query: Best ice cream in Verona?\n",
      "Session: Best ice cream in Verona? | Best riverside walk | Handy parking to start a walking tour of the center? | A scenic evening walk with minimal stairs? | Train schedule from Verona to Milan\n",
      "Article Title: Gelateria La Romana\n",
      "Article Text: Gelateria La Romana (Ristorazione): Part of the La Romana artisanal chain, the Verona branch opened in 2013 on Piazza Santo Spirito 9. It pairs gelato made with a franchise-wide focus on ingredients with pastries and café service, offering both classic Italian flavors and rotating specials. Seating and takeaway cater to the evening passeggiata as well as daytime visits.\n",
      "The brand communicates product and store details via dedicated shop pages.\n",
      "\n",
      "Personal Entities: verona | italian | café | the la romana | piazza santo spirito 9\n",
      "\n",
      "ORCID Keywords: machine learning | natural language processing | data visualization | computational linguistics\n",
      "\n",
      "Based on the above query, session, article, personal entities, and ORCID keywords, please generate one next query suggestion with the rationale, in the format of\n",
      "Query Suggestion:\n",
      "Rationale:\n",
      "\n",
      "\u001b[33mGemini next\u001b[0m Query Suggestion: Data visualization of Italian gelato flavor popularity\n",
      "\n",
      "Rationale: This suggestion blends the user's immediate interest in Italian gelato (from the query, session, article, and personal entities) with their long-term academic focus on data visualization (from ORCID keywords). It offers a novel exploration of a relevant topic, moving beyond simply finding the best ice cream to understanding broader trends. This acknowledges the user's academic background while keeping the current interest in Italian food culture as a focal point.  It avoids directly reusing search terms while maintaining topical relevance.\n",
      "\n",
      "\u001b[36m=== USER u2 - database management professor ===\u001b[0m\n",
      "\n",
      "=== SYSTEM ===\n",
      "\n",
      "You are an AI assistant whose primary goal is to suggest a next search query, in order to help a user search and find information better on the search engine. Two different queries and entities are separated by the token '|'. For example,'Microsoft' and 'Google' would appear as 'Microsoft' | 'Google'.\n",
      "\n",
      "=== USER ===\n",
      "\n",
      "You are going to suggest ONE next search query based on the current query, the current session, the current article, the user's personal entities, and the user's ORCID keywords.\n",
      "\n",
      "Guidance and priorities:\n",
      "- Prioritize long-term user relevance from ORCID keywords (≈50%).\n",
      "- Maintain session intent continuity without lexical repetition (≈25%).\n",
      "- Use the article only as supporting context (cap ≈25%).\n",
      "- Favor novelty and depth over logistics unless the session explicitly shows planning intent.\n",
      "Definitions:\n",
      "- The query is a specific set of phrases that the user enters into the search engine to find the information or resources related to a particular topic, question, or interest.\n",
      "- The session refers to a sequence of queries requested by the user on the search engine, within a certain period of time or with regard to the completion of a task.\n",
      "- The article refers to a specific webpage that the user clicks and reads from several search results displayed by the search engine in response to the requested query.\n",
      "- The personal entity refers to a topic, keyword, person, event, or any subject that is specifically relevant or appealing to the individual user based on their personal interests.\n",
      "- The ORCID keywords refer to self-declared research topics and academic interests from the user's ORCID profile. They provide a stable signal of long-term expertise or focus areas, complementing the personal entities extracted from recent interactions.\n",
      "\n",
      "Read the following query, session, article, and personal entities of the user as the context information, which might be helpful and relevant to suggest the next query.\n",
      "\n",
      "Query: Best ice cream in Verona?\n",
      "Session: Best ice cream in Verona? | Most important church to visit in Verona? | Are there guided tours at the Roman Theatre museum? | Roman bridge with the best photo spot over the Adige | How to get from Verona Airport to the historic center\n",
      "Article Title: Gelateria La Romana\n",
      "Article Text: Gelateria La Romana (Ristorazione): Part of the La Romana artisanal chain, the Verona branch opened in 2013 on Piazza Santo Spirito 9. It pairs gelato made with a franchise-wide focus on ingredients with pastries and café service, offering both classic Italian flavors and rotating specials. Seating and takeaway cater to the evening passeggiata as well as daytime visits.\n",
      "The brand communicates product and store details via dedicated shop pages.\n",
      "\n",
      "Personal Entities: italian | verona | café | the la romana | piazza santo spirito 9\n",
      "\n",
      "ORCID Keywords: database | data science | ethics in data management | recommender systems | context awareness | personalization\n",
      "\n",
      "Based on the above query, session, article, personal entities, and ORCID keywords, please generate one next query suggestion with the rationale, in the format of\n",
      "Query Suggestion:\n",
      "Rationale:\n",
      "\n",
      "\u001b[33mGemini next\u001b[0m Query Suggestion: Recommender systems for personalized gelato flavor suggestions\n",
      "\n",
      "Rationale: This query blends the user's immediate interest in gelato (from the query, session, and article) with their long-term ORCID keyword focus on recommender systems and personalization.  It acknowledges the context of the article (Gelateria La Romana with rotating specials) and offers a novel direction for exploration that aligns with the user's likely expertise. This moves beyond simply finding good ice cream and explores the potential for personalized recommendations in that domain.\n",
      "\n",
      "\u001b[36m=== USER u3 - Physician ===\u001b[0m\n",
      "\n",
      "=== SYSTEM ===\n",
      "\n",
      "You are an AI assistant whose primary goal is to suggest a next search query, in order to help a user search and find information better on the search engine. Two different queries and entities are separated by the token '|'. For example,'Microsoft' and 'Google' would appear as 'Microsoft' | 'Google'.\n",
      "\n",
      "=== USER ===\n",
      "\n",
      "You are going to suggest ONE next search query based on the current query, the current session, the current article, the user's personal entities, and the user's ORCID keywords.\n",
      "\n",
      "Guidance and priorities:\n",
      "- Prioritize long-term user relevance from ORCID keywords (≈50%).\n",
      "- Maintain session intent continuity without lexical repetition (≈25%).\n",
      "- Use the article only as supporting context (cap ≈25%).\n",
      "- Favor novelty and depth over logistics unless the session explicitly shows planning intent.\n",
      "Definitions:\n",
      "- The query is a specific set of phrases that the user enters into the search engine to find the information or resources related to a particular topic, question, or interest.\n",
      "- The session refers to a sequence of queries requested by the user on the search engine, within a certain period of time or with regard to the completion of a task.\n",
      "- The article refers to a specific webpage that the user clicks and reads from several search results displayed by the search engine in response to the requested query.\n",
      "- The personal entity refers to a topic, keyword, person, event, or any subject that is specifically relevant or appealing to the individual user based on their personal interests.\n",
      "- The ORCID keywords refer to self-declared research topics and academic interests from the user's ORCID profile. They provide a stable signal of long-term expertise or focus areas, complementing the personal entities extracted from recent interactions.\n",
      "\n",
      "Read the following query, session, article, and personal entities of the user as the context information, which might be helpful and relevant to suggest the next query.\n",
      "\n",
      "Query: Best ice cream in Verona?\n",
      "Session: Best ice cream in Verona? | Which is the cathedral of Verona? | Where can I buy opera tickets? | How can I visit Castelvecchio | Best place for a traditional Veronese dinner?\n",
      "Article Title: Gelateria La Romana\n",
      "Article Text: Gelateria La Romana (Ristorazione): Part of the La Romana artisanal chain, the Verona branch opened in 2013 on Piazza Santo Spirito 9. It pairs gelato made with a franchise-wide focus on ingredients with pastries and café service, offering both classic Italian flavors and rotating specials. Seating and takeaway cater to the evening passeggiata as well as daytime visits.\n",
      "The brand communicates product and store details via dedicated shop pages.\n",
      "\n",
      "Personal Entities: verona | italian | café | the la romana | piazza santo spirito 9\n",
      "\n",
      "ORCID Keywords: diabetes | metabolism | pancreatic beta cell function | insulin-resistance\n",
      "\n",
      "Based on the above query, session, article, personal entities, and ORCID keywords, please generate one next query suggestion with the rationale, in the format of\n",
      "Query Suggestion:\n",
      "Rationale:\n",
      "\n",
      "\u001b[33mGemini next\u001b[0m Query Suggestion: Glycemic index of gelato ingredients\n",
      "\n",
      "Rationale: This suggestion bridges the user's immediate interest in gelato (from the query, session, and article) with their long-term research focus on diabetes and metabolism (ORCID keywords).  It acknowledges the enjoyment of gelato while suggesting a deeper dive into its nutritional aspects, specifically the glycemic index, relevant to managing blood sugar levels. This adds a novel dimension to the search, moving beyond simply finding the \"best\" gelato to understanding its composition.  It avoids direct repetition of previous searches but maintains thematic consistency with the current session’s focus on food and Verona.\n",
      "\n",
      "\u001b[36m=== USER u4 - Student ===\u001b[0m\n",
      "\n",
      "=== SYSTEM ===\n",
      "\n",
      "You are an AI assistant whose primary goal is to suggest a next search query, in order to help a user search and find information better on the search engine. Two different queries and entities are separated by the token '|'. For example,'Microsoft' and 'Google' would appear as 'Microsoft' | 'Google'.\n",
      "\n",
      "=== USER ===\n",
      "\n",
      "You are going to suggest ONE next search query based on the current query, the current session, the current article, the user's personal entities, and the user's ORCID keywords.\n",
      "\n",
      "Guidance and priorities:\n",
      "- Prioritize long-term user relevance from ORCID keywords (≈50%).\n",
      "- Maintain session intent continuity without lexical repetition (≈25%).\n",
      "- Use the article only as supporting context (cap ≈25%).\n",
      "- Favor novelty and depth over logistics unless the session explicitly shows planning intent.\n",
      "Definitions:\n",
      "- The query is a specific set of phrases that the user enters into the search engine to find the information or resources related to a particular topic, question, or interest.\n",
      "- The session refers to a sequence of queries requested by the user on the search engine, within a certain period of time or with regard to the completion of a task.\n",
      "- The article refers to a specific webpage that the user clicks and reads from several search results displayed by the search engine in response to the requested query.\n",
      "- The personal entity refers to a topic, keyword, person, event, or any subject that is specifically relevant or appealing to the individual user based on their personal interests.\n",
      "- The ORCID keywords refer to self-declared research topics and academic interests from the user's ORCID profile. They provide a stable signal of long-term expertise or focus areas, complementing the personal entities extracted from recent interactions.\n",
      "\n",
      "Read the following query, session, article, and personal entities of the user as the context information, which might be helpful and relevant to suggest the next query.\n",
      "\n",
      "Query: Best ice cream in Verona?\n",
      "Session: Best ice cream in Verona? | Where to drink something in the evening? | Which exhibition center hosts Vinitaly in Verona? | Best cinema in Verona | Where does the Castel San Pietro funicular depart from?\n",
      "Article Title: Gelateria La Romana\n",
      "Article Text: Gelateria La Romana (Ristorazione): Part of the La Romana artisanal chain, the Verona branch opened in 2013 on Piazza Santo Spirito 9. It pairs gelato made with a franchise-wide focus on ingredients with pastries and café service, offering both classic Italian flavors and rotating specials. Seating and takeaway cater to the evening passeggiata as well as daytime visits.\n",
      "The brand communicates product and store details via dedicated shop pages.\n",
      "\n",
      "Personal Entities: verona | italian | café | the la romana | piazza santo spirito 9\n",
      "\n",
      "ORCID Keywords: \n",
      "\n",
      "Based on the above query, session, article, personal entities, and ORCID keywords, please generate one next query suggestion with the rationale, in the format of\n",
      "Query Suggestion:\n",
      "Rationale:\n",
      "\n",
      "\u001b[33mGemini next\u001b[0m Query Suggestion: \"gelato shops near Piazza delle Erbe Verona\"\n",
      "\n",
      "Rationale: This suggestion builds upon the initial query and session history, which focuses on finding good food and drink experiences in Verona. It acknowledges the user's visit to the Gelateria La Romana article and their interest in \"gelato,\" while also introducing a new location (\"Piazza delle Erbe\"), which is another popular spot in Verona. This encourages exploration of different options while staying within the established interest in food and drink within Verona.  Since there are no ORCID keywords provided, the suggestion is based primarily on session continuity and expanding on the current article context by seeking similar options in a different location.\n",
      "\n",
      "\u001b[36m=== USER u5 - Sport science researcher ===\u001b[0m\n",
      "\n",
      "=== SYSTEM ===\n",
      "\n",
      "You are an AI assistant whose primary goal is to suggest a next search query, in order to help a user search and find information better on the search engine. Two different queries and entities are separated by the token '|'. For example,'Microsoft' and 'Google' would appear as 'Microsoft' | 'Google'.\n",
      "\n",
      "=== USER ===\n",
      "\n",
      "You are going to suggest ONE next search query based on the current query, the current session, the current article, the user's personal entities, and the user's ORCID keywords.\n",
      "\n",
      "Guidance and priorities:\n",
      "- Prioritize long-term user relevance from ORCID keywords (≈50%).\n",
      "- Maintain session intent continuity without lexical repetition (≈25%).\n",
      "- Use the article only as supporting context (cap ≈25%).\n",
      "- Favor novelty and depth over logistics unless the session explicitly shows planning intent.\n",
      "Definitions:\n",
      "- The query is a specific set of phrases that the user enters into the search engine to find the information or resources related to a particular topic, question, or interest.\n",
      "- The session refers to a sequence of queries requested by the user on the search engine, within a certain period of time or with regard to the completion of a task.\n",
      "- The article refers to a specific webpage that the user clicks and reads from several search results displayed by the search engine in response to the requested query.\n",
      "- The personal entity refers to a topic, keyword, person, event, or any subject that is specifically relevant or appealing to the individual user based on their personal interests.\n",
      "- The ORCID keywords refer to self-declared research topics and academic interests from the user's ORCID profile. They provide a stable signal of long-term expertise or focus areas, complementing the personal entities extracted from recent interactions.\n",
      "\n",
      "Read the following query, session, article, and personal entities of the user as the context information, which might be helpful and relevant to suggest the next query.\n",
      "\n",
      "Query: Best ice cream in Verona?\n",
      "Session: Best ice cream in Verona? | Most important church to visit in Verona? | Are there guided tours at the Roman Theatre museum? | Roman bridge with the best photo spot over the Adige | How to get from Verona Airport to the historic center\n",
      "Article Title: Gelateria La Romana\n",
      "Article Text: Gelateria La Romana (Ristorazione): Part of the La Romana artisanal chain, the Verona branch opened in 2013 on Piazza Santo Spirito 9. It pairs gelato made with a franchise-wide focus on ingredients with pastries and café service, offering both classic Italian flavors and rotating specials. Seating and takeaway cater to the evening passeggiata as well as daytime visits.\n",
      "The brand communicates product and store details via dedicated shop pages.\n",
      "\n",
      "Personal Entities: italian | verona | café | the la romana | piazza santo spirito 9\n",
      "\n",
      "ORCID Keywords: Researcher | Sport Teacher | handball and Bodybuilding coach | Sports Equipment Business\n",
      "\n",
      "Based on the above query, session, article, personal entities, and ORCID keywords, please generate one next query suggestion with the rationale, in the format of\n",
      "Query Suggestion:\n",
      "Rationale:\n",
      "\n",
      "\u001b[33mGemini next\u001b[0m Query Suggestion: \"Cafés near Piazza Santo Spirito, Verona, with outdoor seating\"\n",
      "\n",
      "Rationale: This suggestion blends several factors:\n",
      "\n",
      "* **Session Continuity (25%):** The session shows a clear interest in Verona and its attractions, moving from ice cream to churches, Roman ruins, photo spots, and transport.  This query continues the exploration of Verona, focusing on a specific area mentioned in the article (Piazza Santo Spirito) and relevant to the initial \"ice cream\" query. The \"café\" element also connects back to the article mentioning \"café service\".  It avoids lexical repetition of \"ice cream\" or \"Gelateria La Romana\" while staying topically relevant.\n",
      "\n",
      "* **Article Context (25%):** The article mentions \"seating and takeaway cater to the evening passeggiata,\" suggesting outdoor seating might be available.  This query digs deeper into that aspect, which could be relevant to the user's interest in enjoying the area.\n",
      "\n",
      "* **Personal Entities (25%):** It incorporates the user's interest in \"Verona,\" \"café,\"  \"Piazza Santo Spirito 9,\" and indirectly \"Italian\" (as outdoor seating is a common feature of Italian cafés).\n",
      "\n",
      "* **ORCID Keywords (25%):** While the ORCID keywords are focused on sports, they don't directly relate to this specific search.  However, by focusing on pleasant places to relax (cafés with outdoor seating), the query indirectly acknowledges a potential need for leisure and breaks, which is relevant to a busy lifestyle implied by the multiple roles listed in the ORCID profile.  This is a subtle connection, acknowledging the ORCID keywords without forcing a thematic shift.  The slight de-prioritization of ORCID here (25% instead of 50%) is justified by the strong local context established by the other factors.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Model 2: K-LaMP with prompt-weighted ORCID keywords ===\n",
    "\n",
    "print(\"*****************************************************************************\")\n",
    "print(\"=== NEXT QUERY GENERATION WITH K-LAMP PROMPT-WEIGHTED to focus on ORCID ===\\n\")\n",
    "for user in [u1, u2, u3, u4, u5]:\n",
    "    print(f\"\\033[36m=== USER {user['user_id']} - {user['Profession']} ===\\033[0m\")\n",
    "    # Build messages with strategy = familiar | unfamiliar | lapsed\n",
    "    msgs = build_k_lamp_paper_prompt_weighted(\n",
    "    user_row=user,\n",
    "    current_query=current_query,\n",
    "    page_title=page_title,\n",
    "    page_text=page_text,\n",
    "    strategy=\"familiar\",     # \"familiar\" | \"unfamiliar\" | \"lapsed\"\n",
    "    k_entities=5,        \n",
    "    personal_keywords=user[\"orcid__keywords\"],  # from ORCID    \n",
    "    n_session=5          \n",
    "    )\n",
    "\n",
    "    # Print FULL messages\n",
    "    print(\"\\n=== SYSTEM ===\\n\")\n",
    "    print(msgs[\"system\"])\n",
    "\n",
    "    print(\"=== USER ===\\n\")\n",
    "    print(msgs[\"user\"])\n",
    "\n",
    "    # Call Gemini\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"models/gemini-1.5-pro-latest\",\n",
    "        system_instruction=msgs[\"system\"]\n",
    "    )\n",
    "    resp = model.generate_content(msgs[\"user\"])\n",
    "\n",
    "    # Safe print even if resp.text is missing\n",
    "    out_text = getattr(resp, \"text\", \"\") or \"\"\n",
    "    print(f\"\\n\\033[33mGemini next\\033[0m {out_text.strip()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3550695d",
   "metadata": {},
   "source": [
    "**10.2 Enhanced Scenario (Profile-Aware K-LaMP)**\n",
    "\n",
    "This subsection demonstrates the **enhanced K-LaMP prompt**, which integrates ORCID keywords and additional user profile attributes (profession, nationality, interests). \n",
    "\n",
    "For each sample user, it builds the enriched prompt, displays the full *system* and *user* messages, and invokes Gemini to generate a personalized next search query.  \n",
    "\n",
    "Compared to the original paper scenario, this setup emphasizes **long-term profile signals** while still maintaining session continuity and contextual grounding in the current article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d470794d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************************************\n",
      "=== ORCID PROMPT ENHANCED CASE: NEXT QUERY GENERATION WITH K-LAMP PROMPT ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Model 3: K-LaMP with prompt-weighted ORCID + personal interests ===\n",
    "\n",
    "print(\"*****************************************************************************\")\n",
    "print(\"=== ORCID PROMPT ENHANCED CASE: NEXT QUERY GENERATION WITH K-LAMP PROMPT ===\\n\")\n",
    "#for user in [u1, u2, u3, u4, u5]:\n",
    "    #print(f\"\\033[36m=== USER {user['user_id']} - {user['Profession']} ===\\033[0m\")\n",
    "    # Build messages with strategy = familiar | unfamiliar | lapsed\n",
    "    #msgs = build_k_lamp_prompt_enhanced(\n",
    "    #user_row=user,\n",
    "    #current_query=current_query,\n",
    "    #page_title=page_title,\n",
    "    #page_text=page_text,\n",
    "    #strategy=\"familiar\",     # \"familiar\" | \"unfamiliar\" | \"lapsed\"\n",
    "    #k_entities=5,        \n",
    "    #personal_keywords=user[\"orcid__keywords\"],  # from ORCID    \n",
    "    #n_session=None          \n",
    "    #)\n",
    "\n",
    "    # Print FULL messages\n",
    "    #print(\"\\n=== SYSTEM ===\\n\")\n",
    "    #print(msgs[\"system\"])\n",
    "\n",
    "    #print(\"\\n=== USER ===\\n\")\n",
    "    #print(msgs[\"user\"])\n",
    "\n",
    "    # Call Gemini\n",
    "    #model = genai.GenerativeModel(\n",
    "    #    model_name=\"models/gemini-1.5-pro-latest\",\n",
    "    #    system_instruction=msgs[\"system\"]\n",
    "    #)\n",
    "    #resp = model.generate_content(msgs[\"user\"])\n",
    "\n",
    "    # Safe print even if resp.text is missing\n",
    "    #out_text = getattr(resp, \"text\", \"\") or \"\"\n",
    "    #print(f\"\\n\\033[33mGemini next\\033[0m {out_text.strip()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32b14bb",
   "metadata": {},
   "source": [
    "## 11. Conclusions & Next Steps\n",
    "\n",
    "This notebook re-implemented the K-LaMP framework for **personalized contextual query suggestion**.  \n",
    "The workflow demonstrated:  \n",
    "1. Loading and merging datasets (POIs, descriptions, user profiles).  \n",
    "2. Building a **memory stream** of user interactions (queries, POI views, ORCID keywords).  \n",
    "3. Constructing an **entity store** to aggregate entities with counts and timestamps.  \n",
    "4. Designing prompt builders (original K-LaMP vs. enhanced version with profile integration).  \n",
    "5. Using the **Gemini API** to generate next-query suggestions under different scenarios.  \n",
    "\n",
    "**Key takeaway:**  \n",
    "\n",
    "Entity-centric personalization, especially when combined with **ORCID profiles** and user attributes, yields richer and more relevant query recommendations compared to a baseline prompt.  \n",
    "\n",
    "**Future directions:**  \n",
    "- Develop automatic evaluation metrics to quantify personalization quality.   \n",
    "- Investigate alternative retrieval strategies (familiar, unfamiliar, lapsed) and dynamic weighting schemes.  \n",
    "- Assess scalability on larger and more diverse user datasets, including longer interaction histories.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09a4dc1",
   "metadata": {},
   "source": [
    "## 12. Sandbox for Next-Query Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9176dc20",
   "metadata": {},
   "source": [
    "# Sandbox Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a98ea25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 12.1 Helper function  ===\n",
    "\n",
    "from typing import Literal, Tuple\n",
    "\n",
    "def _resolve_poi(poi_selector) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Resolve a POI from `merged_df` given either:\n",
    "    - an integer row index\n",
    "    - a string 'poi_name'\n",
    "    Returns (page_title, page_text).\n",
    "    \"\"\"\n",
    "    if isinstance(poi_selector, int):\n",
    "        row = merged_df.iloc[poi_selector]\n",
    "    else:\n",
    "        # fallback: first match by name (case-insensitive)\n",
    "        m = merged_df[merged_df[\"poi_name\"].str.lower() == str(poi_selector).lower()]\n",
    "        if m.empty:\n",
    "            # try substring search\n",
    "            m = merged_df[merged_df[\"poi_name\"].str.lower().str.contains(str(poi_selector).lower(), na=False)]\n",
    "        if m.empty:\n",
    "            raise ValueError(f\"POI '{poi_selector}' not found. Use an index (int) or exact/partial name (str).\")\n",
    "        row = m.iloc[0]\n",
    "    title = row[\"poi_name\"]\n",
    "    text  = f\"{row['poi_name']} ({row['category_name']}): {row['descr_trad_value']}\"\n",
    "    return title, text\n",
    "\n",
    "\n",
    "def run_next_query_experiment(\n",
    "    user_id: str,\n",
    "    current_query: str,\n",
    "    poi_selector,                             # int index or poi_name string\n",
    "    strategy: Literal[\"familiar\",\"unfamiliar\",\"lapsed\"] = \"familiar\",\n",
    "    k_entities: int = 5,\n",
    "    n_session: int | None = None,\n",
    "    mode: Literal[\"enhanced\",\"paper\"] = \"enhanced\",\n",
    "    persist: bool = False,                    # if True, log query/page into memory and rebuild ENT store\n",
    "    seed: int = 42\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Run a single next-query experiment with minimal side effects.\n",
    "    - If persist=False (default), it will NOT log anything to memory.\n",
    "    - If persist=True, it logs query+page and rebuilds the entity store.\n",
    "    Returns a dict with inputs, prompt, and Gemini output.\n",
    "    \"\"\"\n",
    "    # Resolve article/page\n",
    "    page_title, page_text = _resolve_poi(poi_selector)\n",
    "\n",
    "    # If requested, persist this interaction to the memory stream\n",
    "    if persist:\n",
    "        log_query_event(current_query, user_id)\n",
    "        # Build a minimal fake row-like object for page logging\n",
    "        class _Row: pass\n",
    "        r = _Row()\n",
    "        setattr(r, \"__getitem__\", lambda _, k: {\"descr_trad_value\": page_text}[k])\n",
    "        log_page_viewed_event({\"descr_trad_value\": page_text}, user_id)  # uses only descr_trad_value\n",
    "        rebuild_entity_store()\n",
    "\n",
    "    # Pick the user row from users_df (already loaded earlier)\n",
    "    try:\n",
    "        user_row = users_df.loc[user_id]\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Unknown user_id '{user_id}'. Available: {list(users_df['user_id'])}\") from e\n",
    "\n",
    "    # Prepare ORCID keywords if present\n",
    "    personal_keywords = user_row.get(\"orcid__keywords\", [])\n",
    "\n",
    "    # Build prompt\n",
    "    if mode == \"enhanced\":\n",
    "        msgs = build_k_lamp_prompt_enhanced(\n",
    "            user_row=user_row,\n",
    "            current_query=current_query,\n",
    "            page_title=page_title,\n",
    "            page_text=page_text,\n",
    "            strategy=strategy,\n",
    "            k_entities=k_entities,\n",
    "            personal_keywords=personal_keywords,\n",
    "            n_session=n_session,\n",
    "        )\n",
    "    else:\n",
    "        msgs = build_k_lamp_paper_prompt_weighted(\n",
    "            user_row=user_row,\n",
    "            current_query=current_query,\n",
    "            page_title=page_title,\n",
    "            page_text=page_text,\n",
    "            strategy=strategy,\n",
    "            k_entities=k_entities,\n",
    "            personal_keywords=personal_keywords,\n",
    "            n_session=n_session,\n",
    "        )\n",
    "\n",
    "    # Call Gemini (reuse `model` if available; otherwise create a local one)\n",
    "    _model = genai.GenerativeModel(\n",
    "    model_name=\"models/gemini-1.5-pro-latest\",\n",
    "    system_instruction=msgs[\"system\"]\n",
    "    )   \n",
    "\n",
    "    # Now generate using only the user message\n",
    "    resp = _model.generate_content(msgs[\"user\"])\n",
    "    out_text = getattr(resp, \"text\", \"\") or \"\"\n",
    "\n",
    "    if mode == \"enhanced\":\n",
    "        print(f\"\\033[36m=== USER {user_id} - {user_row.get('Profession')} ===\\033[0m\")\n",
    "        print(\"\\n=== CONTEXT ===\\n\")\n",
    "        print(f\"\\033[31mCurrent query:\\033[0m {current_query}\")\n",
    "        print(f\"\\033[31mPage title:\\033[0m {page_title}\") \n",
    "        print(f\"\\033[31mPage text:\\033[0m {page_text[:300]}\")\n",
    "        print(f\"\\033[31mStrategy:\\033[0m {strategy}\")\n",
    "        print(f\"\\033[31mPersonal keywords (ORCID):\\033[0m {personal_keywords}\")\n",
    "        print(f\"\\033[31mSession queries (last {n_session or 'all'}):\\033[0m {get_session_queries(user_id, n=n_session, order='desc')}\")\n",
    "        print(f\"\\033[31mPersonal entities (K-LaMP):\\033[0m {pick_personal_entities_k_lamp(user_id, current_query, page_text, strategy=strategy, k=k_entities, seed=seed)}\")\n",
    "        print(f\"\\033[31mPersona interests:\\033[0m {user_row.get('Personal Interest')}\")\n",
    "          \n",
    "        print(f\"\\n\\033[33mGemini next\\033[0m {out_text.strip()}\\n\")\n",
    "    \n",
    "    elif mode == \"paper\":\n",
    "        print(f\"\\033[36m=== USER {user_id}\\033[0m\")\n",
    "        print(\"\\n=== CONTEXT ===\\n\")\n",
    "        print(f\"\\033[31mCurrent query:\\033[0m {current_query}\")\n",
    "        print(f\"\\033[31mPage title:\\033[0m {page_title}\") \n",
    "        print(f\"\\033[31mPage text:\\033[0m {page_text[:300]}\")\n",
    "        print(f\"\\033[31mStrategy:\\033[0m {strategy}\")\n",
    "        print(f\"\\033[31mPersonal keywords (ORCID):\\033[0m {personal_keywords}\")\n",
    "        print(f\"\\033[31mSession queries (last {n_session or 'all'}):\\033[0m {get_session_queries(user_id, n=n_session, order='desc')}\")\n",
    "        print(f\"\\033[31mPersonal entities (K-LaMP):\\033[0m {pick_personal_entities_k_lamp(user_id, current_query, page_text, strategy=strategy, k=k_entities, seed=seed)}\")\n",
    "\n",
    "\n",
    "          \n",
    "        print(f\"\\n\\033[33mGemini next\\033[0m {out_text.strip()}\\n\")\n",
    "\n",
    "\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb29ade",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63c59d1",
   "metadata": {},
   "source": [
    "Enhanced: Prompt and Personal Interests (Model 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "91f8c539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== USER u1 - mathematics professor ===\u001b[0m\n",
      "\n",
      "=== CONTEXT ===\n",
      "\n",
      "\u001b[31mCurrent query:\u001b[0m Gorillaz concert dates\n",
      "\u001b[31mPage title:\u001b[0m Stadio Marcantonio Bentegodi\n",
      "\u001b[31mPage text:\u001b[0m Stadio Marcantonio Bentegodi (Servizi): Stadio Marcantonio Bentegodi is Verona’s principal multi-purpose stadium and the home ground of Hellas Verona; with an overall capacity of about 39,000 (roughly 31,000 approved), it ranks among Italy’s larger venues. Designed by engineer Leopoldo Baruchello wi\n",
      "\u001b[31mStrategy:\u001b[0m familiar\n",
      "\u001b[31mPersonal keywords (ORCID):\u001b[0m ['machine learning', 'natural language processing', 'data visualization', 'computational linguistics']\n",
      "\u001b[31mSession queries (last all):\u001b[0m ['Best ice cream in Verona?', 'Best riverside walk', 'Handy parking to start a walking tour of the center?', 'A scenic evening walk with minimal stairs?', 'Train schedule from Verona to Milan', 'Ice cream shops near the Arena in Verona', 'Top-rated museums in Verona', 'Best restaurants in Verona']\n",
      "\u001b[31mPersonal entities (K-LaMP):\u001b[0m ['verona', 'marcantonio bentegodi']\n",
      "\u001b[31mPersona interests:\u001b[0m ['Artificial Intelligence', 'technology', 'travel', 'science', 'food', 'music']\n",
      "\n",
      "\u001b[33mGemini next\u001b[0m Query Suggestion: NLP applications in music\n",
      "Rationale: The user's initial query about concert dates and the mention of concerts in the article suggest an interest in music, aligning with their stated personal interests. However, prioritizing their ORCID keywords (machine learning, natural language processing, etc.) and profession (mathematics professor), the suggestion pivots towards a more academic/professional angle related to music. \"NLP applications in music\" combines the user's interest in music with their expertise in NLP, offering a novel exploration within their field. This caters to long-term relevance and potential research interests rather than just immediate informational needs. It avoids lexical repetition from the initial query while staying within the broader context of music.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enhanced, familiar, by POI index\n",
    "run_next_query_experiment(\n",
    "    user_id=\"u1\",\n",
    "    current_query=\"Gorillaz concert dates\",\n",
    "    poi_selector=43,                   # row index\n",
    "    strategy=\"familiar\",\n",
    "    k_entities=5,\n",
    "    mode=\"enhanced\",\n",
    "    persist=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cd5bfe",
   "metadata": {},
   "source": [
    "Prompt Enhanced to focus on ORCID keywords (Model 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "190b8ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m=== USER u4\u001b[0m\n",
      "\n",
      "=== CONTEXT ===\n",
      "\n",
      "\u001b[31mCurrent query:\u001b[0m What to do tonight\n",
      "\u001b[31mPage title:\u001b[0m Piazza Bra\n",
      "\u001b[31mPage text:\u001b[0m Piazza Bra (Monumenti): This square gives a magnificent glance on the history of the city: it is the foyer of the Arena on occasion of the opera, which draws thousand of spectators. It is the place where the people from Verona like strolling for more than two centuries – along the Liston: between 17\n",
      "\u001b[31mStrategy:\u001b[0m familiar\n",
      "\u001b[31mPersonal keywords (ORCID):\u001b[0m []\n",
      "\u001b[31mSession queries (last all):\u001b[0m ['Best ice cream in Verona?', 'Where to drink something in the evening?', 'Which exhibition center hosts Vinitaly in Verona?', 'Best cinema in Verona', 'Where does the Castel San Pietro funicular depart from?', 'Pastry shop in Verona known for the traditional Nadalin', 'Historic wine bar in the center', 'Artisanal gelato a minute from Piazza Bra', 'Nightclub in Verona with two levels', 'Nightclub with a panoramic terrace overlooking the city', 'Where to watch a football match in Verona?', '24/7 parking near the Arena for an evening show']\n",
      "\u001b[31mPersonal entities (K-LaMP):\u001b[0m ['verona', 'arena', 'piazza bra']\n",
      "\n",
      "\u001b[33mGemini next\u001b[0m Query Suggestion: Events in Piazza Bra Verona tonight\n",
      "\n",
      "Rationale: The user's session shows a clear intent to find things to do in Verona tonight.  The current query (\"What to do tonight\") is very broad, and the clicked article about Piazza Bra suggests this location is of interest. The personal entities reinforce the interest in Verona, the Arena, and Piazza Bra. By combining these elements, the suggested query seeks to provide more specific and relevant results about events happening in Piazza Bra tonight.  Since no ORCID keywords are provided, the focus remains entirely on the current session and immediate interests.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Paper-style prompt, by POI name\n",
    "run_next_query_experiment(\n",
    "    user_id=\"u4\",\n",
    "    current_query=\"What to do tonight\",\n",
    "    poi_selector=10,    \n",
    "    strategy=\"familiar\",\n",
    "    k_entities=5,\n",
    "    mode=\"paper\",\n",
    "    persist=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data_Science_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
